# Explainable AI (XAI) with Variational Autoencoders

This repository explores Explainable Artificial Intelligence (XAI) techniques, focusing primarily on Variational Autoencoders (VAEs). It includes implementations of basic autoencoders, VAEs, and experiments with interpretability methods like SHAP and LIME to help understand the decisions made by these models.

## üìÅ Repository Structure

- `AE-VAE.ipynb`: Introduces Autoencoders and VAEs with intuitive visualizations and explanations.
- `VAE-BCE.ipynb`: Trains a VAE using Binary Cross-Entropy loss, showcasing reconstruction quality and latent space exploration.
- `VAE_full.ipynb`: A complete implementation of VAE training with visualization and evaluation steps.
- `XAI_Test.ipynb`: Applies XAI methods (e.g., SHAP, LIME) to interpret VAE models.

## üöÄ Getting Started

### Prerequisites

- Python 3.7+
- Jupyter Notebook
- Recommended packages:
  - `numpy`
  - `pandas`
  - `matplotlib`
  - `seaborn`
  - `scikit-learn`
  - `tensorflow` or `torch`
  - `shap`
  - `lime`

### Installation

1. Clone the repository:

```bash
git clone https://github.com/melanieyes/explainable-ai.git
cd explainable-ai
